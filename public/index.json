[{"authors":["admin"],"categories":null,"content":"I am a freelancer applying Data Science using R. I studied engineering and economics and have an advanced university degree, which is called Dipl.-Ing. oec. from the Technical University Hamburg. The degree is equivalent to an Masters degree (engineering \u0026amp; economics) today. I started using R during my advanced statistics courses and instantly fell in love with it. For my thesis I used R to train partial recurrent neural networks for time series forecasting. Since then I never stopped using R for Machine Learning \u0026amp; Data Science, now working as freelancer.\nI believe that interacting with other programmers is fundamental to improving your skills. I constantly visit R conferences to learn new skills and meet with other R developers.\nIn the past years my projects focused around tidal data and offshore windenergy.\nIn my spare time I work on Mobile Apps with Java and recently Dart using the Flutter framework.\nFurthermore I like do any kind of sports and recently started doing yoga.\n","date":1572825600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1572879301,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a freelancer applying Data Science using R. I studied engineering and economics and have an advanced university degree, which is called Dipl.-Ing. oec. from the Technical University Hamburg. The degree is equivalent to an Masters degree (engineering \u0026amp; economics) today. I started using R during my advanced statistics courses and instantly fell in love with it. For my thesis I used R to train partial recurrent neural networks for time series forecasting.","tags":null,"title":"Moritz Mueller-Navarra","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Moritz Mueller-Navarra"],"categories":[],"content":"\rHi,\nin this post I illustrate how we can generate NA rows using only data.table function, where you have a date column (or equivalent).\nWe begin by loading the package.\nlibrary(data.table)\r## Warning: Paket \u0026#39;data.table\u0026#39; wurde unter R Version 3.6.1 erstellt\rProblem\rLet us assume you have a data.table with three columns date, value and product. Here date is of type IDate, value \u0026amp; product is integer. You can think of it as sales data, where you observe daily sales for a certain product. Thus giving you a time series for every product. We assume that we only get a new entry, when we actually observe a sale. Let us look at a minimal example.\n(dt \u0026lt;- data.table(date = as.IDate(c(\u0026quot;2019-11-01\u0026quot;,\u0026quot;2019-11-02\u0026quot;, \u0026quot;2019-11-04\u0026quot;, \u0026quot;2019-11-07\u0026quot;)), value = c(3L,4L,1L,8L), product = c(1L,2L,1L,1L)))\r## date value product\r## 1: 2019-11-01 3 1\r## 2: 2019-11-02 4 2\r## 3: 2019-11-04 1 1\r## 4: 2019-11-07 8 1\rsapply(dt, typeof)\r## date value product ## \u0026quot;integer\u0026quot; \u0026quot;integer\u0026quot; \u0026quot;integer\u0026quot;\rFor the date column you get integer, because the IDate class is a integer based date class. Please check ?IDate for more information.\nSince we want a row for every possible date within a certain range, we need to insert rows, where we did not observe anything.\n\rSolution\rIt is obvious that we have not sold anything on certain days. Now, our job is to insert rows where we write NA for value by date and product. There are different approaches for this task, we focus on joining. Since we know the start and the end of the time series, we can generate a sequence.\n(seq_dates \u0026lt;- seq(as.IDate(\u0026quot;2019-11-01\u0026quot;), as.IDate(\u0026quot;2019-11-07\u0026quot;), by = \u0026quot;days\u0026quot;))\r## [1] \u0026quot;2019-11-01\u0026quot; \u0026quot;2019-11-02\u0026quot; \u0026quot;2019-11-03\u0026quot; \u0026quot;2019-11-04\u0026quot; \u0026quot;2019-11-05\u0026quot;\r## [6] \u0026quot;2019-11-06\u0026quot; \u0026quot;2019-11-07\u0026quot;\rNow we can use the CJ function from data.table to generate a table. We join dt to the return value of CJ based on the columns date and product\ndt[CJ(product = unique(product), date = seq_dates), on = c(\u0026quot;date\u0026quot;, \u0026quot;product\u0026quot;)]\r## date value product\r## 1: 2019-11-01 3 1\r## 2: 2019-11-02 NA 1\r## 3: 2019-11-03 NA 1\r## 4: 2019-11-04 1 1\r## 5: 2019-11-05 NA 1\r## 6: 2019-11-06 NA 1\r## 7: 2019-11-07 8 1\r## 8: 2019-11-01 NA 2\r## 9: 2019-11-02 4 2\r## 10: 2019-11-03 NA 2\r## 11: 2019-11-04 NA 2\r## 12: 2019-11-05 NA 2\r## 13: 2019-11-06 NA 2\r## 14: 2019-11-07 NA 2\rThe CJ function simply generates a table with all possible combinations of date and product.\nCJ(date = seq_dates, product = unique(dt$product))\r## date product\r## 1: 2019-11-01 1\r## 2: 2019-11-01 2\r## 3: 2019-11-02 1\r## 4: 2019-11-02 2\r## 5: 2019-11-03 1\r## 6: 2019-11-03 2\r## 7: 2019-11-04 1\r## 8: 2019-11-04 2\r## 9: 2019-11-05 1\r## 10: 2019-11-05 2\r## 11: 2019-11-06 1\r## 12: 2019-11-06 2\r## 13: 2019-11-07 1\r## 14: 2019-11-07 2\r\rScalibilty\rWe check the perfomance of the proposed workflow by generating a data.table with two parameters: n_days \u0026amp; n_products. The code below generates random n_days within the year 2019 by product. The value is simply a random integer. This results in an object with 2.5 million rows and three columns.\nseq_dates \u0026lt;- seq(as.IDate(\u0026quot;2019-01-01\u0026quot;), as.IDate(\u0026quot;2019-12-31\u0026quot;), by = \u0026quot;days\u0026quot;)\rn_days \u0026lt;- 250L\rn_products \u0026lt;- 10000L\rdt_large \u0026lt;-data.table(rbindlist(lapply(1:n_products, function(x) {\rdate \u0026lt;- sample(seq_dates, n_days)\rproduct \u0026lt;- rep.int(x, n_days)\rreturn(list(date = date, product = product))\r})), value = sample.int(10, n_products*n_days, replace = TRUE))\rsapply(dt_large, typeof)\r## date product value ## \u0026quot;integer\u0026quot; \u0026quot;integer\u0026quot; \u0026quot;integer\u0026quot;\rAfter generating dt_large using CJ we get dt_large_na with 3.65 million rows (365 days * n_products).\nsystem.time(dt_large_na \u0026lt;- dt_large[CJ(product = unique(product), date = seq_dates), on = c(\u0026quot;date\u0026quot;,\u0026quot;product\u0026quot;)])\r## User System verstrichen ## 1.34 0.04 1.19\rdt_large_na\r## date product value\r## 1: 2019-01-01 1 NA\r## 2: 2019-01-02 1 NA\r## 3: 2019-01-03 1 NA\r## 4: 2019-01-04 1 NA\r## 5: 2019-01-05 1 NA\r## --- ## 3649996: 2019-12-27 10000 2\r## 3649997: 2019-12-28 10000 5\r## 3649998: 2019-12-29 10000 8\r## 3649999: 2019-12-30 10000 7\r## 3650000: 2019-12-31 10000 NA\rThus we get NA when we did not observe a value for a certain product and date.\ndt_large_na[product == 1]\r## date product value\r## 1: 2019-01-01 1 NA\r## 2: 2019-01-02 1 NA\r## 3: 2019-01-03 1 NA\r## 4: 2019-01-04 1 NA\r## 5: 2019-01-05 1 NA\r## --- ## 361: 2019-12-27 1 1\r## 362: 2019-12-28 1 NA\r## 363: 2019-12-29 1 8\r## 364: 2019-12-30 1 3\r## 365: 2019-12-31 1 1\rdt_large_na[product == 5]\r## date product value\r## 1: 2019-01-01 5 9\r## 2: 2019-01-02 5 5\r## 3: 2019-01-03 5 NA\r## 4: 2019-01-04 5 4\r## 5: 2019-01-05 5 NA\r## --- ## 361: 2019-12-27 5 5\r## 362: 2019-12-28 5 6\r## 363: 2019-12-29 5 10\r## 364: 2019-12-30 5 NA\r## 365: 2019-12-31 5 8\r\rFilling missing values\rWe generated a data.table with missing values by joining. There are a lot of techniques to fill NA. I want to quickly demonstrate how you can use the nafill function included in data.table. I introduce a new column in dt_large_na to demonstrate the functionality.\ndt_large_na[, filled_value := nafill(value, \u0026quot;locf\u0026quot;), by = \u0026quot;product\u0026quot;]\rThis simply fills the NA values on a product level by last observation carried forward (locf). You might want to use a more sophisticated approach for real data.\ndt_large_na\r## date product value filled_value\r## 1: 2019-01-01 1 NA NA\r## 2: 2019-01-02 1 NA NA\r## 3: 2019-01-03 1 NA NA\r## 4: 2019-01-04 1 NA NA\r## 5: 2019-01-05 1 NA NA\r## --- ## 3649996: 2019-12-27 10000 2 2\r## 3649997: 2019-12-28 10000 5 5\r## 3649998: 2019-12-29 10000 8 8\r## 3649999: 2019-12-30 10000 7 7\r## 3650000: 2019-12-31 10000 NA 7\rImputing missing values requires a lot more thought for real applications. A good ressource is https://rmisstastic.netlify.com/how-to/impute/missimp.\nSee you soon,\nMoritz\n\r","date":1572825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572879301,"objectID":"3bbe00fbf1bac2f4e8bc44178d8f1c5c","permalink":"/post/data-table-cross-joining-i/","publishdate":"2019-11-04T00:00:00Z","relpermalink":"/post/data-table-cross-joining-i/","section":"post","summary":"Hi,\nin this post I illustrate how we can generate NA rows using only data.table function, where you have a date column (or equivalent).\nWe begin by loading the package.\nlibrary(data.table)\r## Warning: Paket \u0026#39;data.table\u0026#39; wurde unter R Version 3.6.1 erstellt\rProblem\rLet us assume you have a data.table with three columns date, value and product. Here date is of type IDate, value \u0026amp; product is integer. You can think of it as sales data, where you observe daily sales for a certain product.","tags":["data.table","cross join","time series","missing values"],"title":"data.table - Generate and Fill missing values.","type":"post"},{"authors":["Moritz Mueller-Navarra"],"categories":[],"content":"\rHi,\nI just submitted the new version of TideCurves to CRAN. You should be able to download version 0.0.4 in the following days.\rIn the previous version 0.0.3 we used a set of 43 partial tides. This set has now been updated by Andreas Boesch and Sylvin Mueller-Navarra. In version 0.0.4 we use a new set of 39 partial tides. Please look out for the new version on CRAN. https://cran.r-project.org/web/packages/TideCurves/index.html and a new post explaining the usage of this package. The TideTables package, currently in version 0.0.2, will also be updatet in the next week(s).\nSee you soon!\rMoritz\n","date":1572307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572352219,"objectID":"34e0c4760add220ccc5080c14192fba3","permalink":"/post/tidecurves-new-version-on-cran/","publishdate":"2019-10-29T00:00:00Z","relpermalink":"/post/tidecurves-new-version-on-cran/","section":"post","summary":"Hi,\nI just submitted the new version of TideCurves to CRAN. You should be able to download version 0.0.4 in the following days.\rIn the previous version 0.0.3 we used a set of 43 partial tides. This set has now been updated by Andreas Boesch and Sylvin Mueller-Navarra. In version 0.0.4 we use a new set of 39 partial tides. Please look out for the new version on CRAN. https://cran.","tags":["R package","tides","TideCurves"],"title":"TideCurves - new version on CRAN","type":"post"},{"authors":["Moritz Mueller-Navarra"],"categories":[],"content":"\rThis is the first post looking at the data.table presentations from useR!2019 which was held in Toulouse from 2019-07-07 to 2019-10-10. For starters we are going to take a look at the presentations from Arun Srinivasan, one of the main developers of data.table. His talk is called THE #RDATATABLEPACKAGE\rfor fast, flexible and memory efficient data wrangling.\nTalk Agenda:\n\rGeneral data.table syntax\rExplaining .SD \u0026amp; .SDcols\rOptimisation \u0026amp; new functionalities\r\rGeneral data.table syntax\rFollowing code chunk installs the development version of the package, which is needed for some functions explained below.\ninstall.packages(\u0026quot;data.table\u0026quot;, repos=\u0026quot;https://Rdatatable.gitlab.io/data.table\u0026quot;)\rWe start of with a simple expample.\nlibrary(\u0026quot;data.table\u0026quot;)\r## Warning: Paket \u0026#39;data.table\u0026#39; wurde unter R Version 3.6.1 erstellt\rWe define a data.table DT using the fread function.\n(DT \u0026lt;- fread(\u0026quot;id code valA valB\r1 c 1 10\r1 b 2 11\r1 c 3 12\r1 c 4 13\r2 a 5 14\r2 a 6 15\r1 b 7 16\r2 a 8 17\r1 c 9 18\u0026quot;))\r## id code valA valB\r## 1: 1 c 1 10\r## 2: 1 b 2 11\r## 3: 1 c 3 12\r## 4: 1 c 4 13\r## 5: 2 a 5 14\r## 6: 2 a 6 15\r## 7: 1 b 7 16\r## 8: 2 a 8 17\r## 9: 1 c 9 18\rThe general data.table syntax is DT[i, j, by], which you can translate into: i = on which rows, j = what to do (columns), grouped by what. So when we want to get the sum of valA, we can simply do.\nDT[, sum(valA)]\r## [1] 45\rWe have not defined a i nor by argument here. This simply means we want to compute for all rows and grouping is not relevant. Now we group by id.\nDT[, sum(valA), by = id]\r## id V1\r## 1: 1 26\r## 2: 2 19\rWe can also name the outcome of the column directly. The .() is an alias for list.\nDT[, .(sumA = sum(valA)), by = id]\r## id sumA\r## 1: 1 26\r## 2: 2 19\rWhen you pass a column to the by argument, internally the number of the unique values for that column gets evaluated. Afterwards the rows are associated to the respective group. Then the expression provided in j, sum(valA) gets evaluated for the groups.\nThis is a very simple example, but illustrates the general form quite nicely. Arun introduces another simple example by passing an expression to the i argument.\nDT[code != \u0026quot;b\u0026quot;, .(sumA = sum(valA)), by = id]\r## id sumA\r## 1: 1 17\r## 2: 2 19\rHere we simply state that code should be not equal to “b”. Very easy and logical syntax.\n\rExplaining .SD \u0026amp; .SDcols\rWe are still operating on DT.\nDT\r## id code valA valB\r## 1: 1 c 1 10\r## 2: 1 b 2 11\r## 3: 1 c 3 12\r## 4: 1 c 4 13\r## 5: 2 a 5 14\r## 6: 2 a 6 15\r## 7: 1 b 7 16\r## 8: 2 a 8 17\r## 9: 1 c 9 18\r.SD stands for Subset of Data. Together with .SDcols we can use it to simply subset DT by column names and then compute on this subset.\nYou could do this:\nDT[, .SD, .SDcols = \u0026quot;valA\u0026quot;]\r## valA\r## 1: 1\r## 2: 2\r## 3: 3\r## 4: 4\r## 5: 5\r## 6: 6\r## 7: 7\r## 8: 8\r## 9: 9\rThis returns a data.table object with one column valA. You can of course pass more columns.\nDT[, .SD, .SDcols = c(\u0026quot;valA\u0026quot;, \u0026quot;valB\u0026quot;)]\r## valA valB\r## 1: 1 10\r## 2: 2 11\r## 3: 3 12\r## 4: 4 13\r## 5: 5 14\r## 6: 6 15\r## 7: 7 16\r## 8: 8 17\r## 9: 9 18\rYou can also use the patterns function in .SDcols.\nDT[, .SD, .SDcols = patterns(\u0026quot;^val\u0026quot;)]\r## valA valB\r## 1: 1 10\r## 2: 2 11\r## 3: 3 12\r## 4: 4 13\r## 5: 5 14\r## 6: 6 15\r## 7: 7 16\r## 8: 8 17\r## 9: 9 18\rHow can we use this functionality to compute the sum of valA and valB grouped by id where code != \"b ?\rEasy :-)\nDT[code != \u0026quot;b\u0026quot;, lapply(.SD, sum), .SDcols = patterns(\u0026quot;^val\u0026quot;), by = \u0026quot;id\u0026quot;]\r## id valA valB\r## 1: 1 17 53\r## 2: 2 19 46\rThe patterns function only returns columns starting with val.\r.SD contains all the columns, except for the grouping columns supplied in by, for each group.\nDT[code != \u0026quot;b\u0026quot;, print(.SD), .SDcols = c(\u0026quot;code\u0026quot;,\u0026quot;valA\u0026quot;, \u0026quot;valB\u0026quot;), by = id]\r## code valA valB\r## 1: c 1 10\r## 2: c 3 12\r## 3: c 4 13\r## 4: c 9 18\r## code valA valB\r## 1: a 5 14\r## 2: a 6 15\r## 3: a 8 17\r## Empty data.table (0 rows and 1 cols): id\rOnce you grouped by id only the columns valA and valB are being considered due to .SDcols. We therefore compute the sums on these columns and not on code.\nDT[code != \u0026quot;b\u0026quot;, print(.SD), .SDcols = c(\u0026quot;valA\u0026quot;, \u0026quot;valB\u0026quot;), by = id]\r## valA valB\r## 1: 1 10\r## 2: 3 12\r## 3: 4 13\r## 4: 9 18\r## valA valB\r## 1: 5 14\r## 2: 6 15\r## 3: 8 17\r## Empty data.table (0 rows and 1 cols): id\rSo how does this lapply(.SD, sum) work? lapply is the infamous base function which returns a list. We operate on .SD and compute the sum of every column in .SD. We take a step back and look at the class and typeof of DT\nclass(DT)\r## [1] \u0026quot;data.table\u0026quot; \u0026quot;data.frame\u0026quot;\rtypeof(DT)\r## [1] \u0026quot;list\u0026quot;\rtypeof(DT[,.SD])\r## [1] \u0026quot;list\u0026quot;\rYou find more information about .SD in this stackoverflow post:\nhttps://stackoverflow.com/questions/8508482/what-does-sd-stand-for-in-data-table-in-r\nYou can also check vignette(\"datatable-sd-usage\") in the development version.\n\rOptimisation \u0026amp; new functionalities\rArun presents optimisation principles for operations in i, j \u0026amp; by.\nOptimisation in “i”\rWe create a data.table which has 200 million rows and two columns x and y.\ndt \u0026lt;- data.table(x = sample(1e5, 2e8, TRUE), y = runif(2e8)) \rNow we only return rows where the value of x is in 1000:2000, we operate in i.\nsystem.time(dt[x %in% 1000:2000])\rsystem.time(dt[x %in% 1000:2000])\rThis takes a while (~17s on my laptop), but running the expression a second time results in a substantial speed up (~4s total). Please note that this not a proper benchmark. The second time we call this the expression, it reuses the index created in the first run. This currently works for == and %in% and is called Auto indexing. The index is stored within the data.table as an attribute.\nNow we create a data.table with 20 columns and 50 million rows to demonstrate that expressions in i can run in parallel.\ndt \u0026lt;- setDT(lapply(1:20, function(x) sample(100, 5e7, TRUE))) \rWe operate in i to return the rows, where V1 \u0026gt; 50L. The column is processed in parallel.\nsystem.time(dt[V1 \u0026gt; 50L])\rYou can set the threads data.table uses with and check the differences.\nsetDTthreads(threads = 1L)\rsystem.time(dt[V1 \u0026gt; 50L])\rsetDTTthreads(threads = 2L)\r\rOptimisation in “by”\rRecently the radix order has been parallelised. We define a new data set (200 million rows, 2 cols, ~3GB).\ndt \u0026lt;- data.table(x=sample(1e5, 2e8, TRUE), y=runif(2e8))\rNow we run this expression, which returns the occurences grouped by x.\ndt[, .N, by = x]\r\rOptimisation in “j”\rIn j certain functions are optimized. Arun mentions mean, median, sum, min, max, head, tail.\rWe can see a difference, when comparing base::mean with just calling mean in j.\ndt[, lapply(.SD, base::mean), by=V1]\rdt[, lapply(.SD, mean), by=V1]\rInternally this expression uses the function mean implemented by data.table in C.\n\r\rNew functionalities\rThe first function we are going to look at is nafill. This function allows us to fill NA values in a data.table by a specific method, like last observation carried forward (locf). See ?data.table::nafill for more information.\nnafill\rnafill is a function that fills missing values in a data.table. We define DT as follows.\n(DT \u0026lt;- fread(\u0026quot;V1 V2 V3 V4\r1 c NA 10\r2 b 2 NA\rNA c 3 NA\r1 NA 4 NA\r2 NA 5 14\u0026quot;))\r## V1 V2 V3 V4\r## 1: 1 c NA 10\r## 2: 2 b 2 NA\r## 3: NA c 3 NA\r## 4: 1 \u0026lt;NA\u0026gt; 4 NA\r## 5: 2 \u0026lt;NA\u0026gt; 5 14\rNow let us try to apply nafill to this object. The function takes in three important arguments:\nnafill(x, type=c(\u0026quot;const\u0026quot;,\u0026quot;locf\u0026quot;,\u0026quot;nocb\u0026quot;), fill=NA,\rverbose=getOption(\u0026quot;datatable.verbose\u0026quot;))\rx can be a vector, list, data.frame or data.table. The type defines how the missing values should be filled.\n\rlocf -\u0026gt; last observation carried forward\rnocb -\u0026gt; next observation carried backwards\rconst -\u0026gt; a constant\r\r#(DT \u0026lt;- nafill(DT, \u0026quot;locf\u0026quot;))\rAbove code will throw an error indicating that we can only fill columns with type numeric (double \u0026amp; integer). Here the setnafill functions comes in handy:\n#getting numeric cols\rnumeric_cols \u0026lt;- names(DT)[DT[, sapply(.SD, is.numeric)]]\rsetnafill(DT, \u0026quot;locf\u0026quot;, cols = numeric_cols)\rDT[]\r## V1 V2 V3 V4\r## 1: 1 c NA 10\r## 2: 2 b 2 10\r## 3: 2 c 3 10\r## 4: 1 \u0026lt;NA\u0026gt; 4 10\r## 5: 2 \u0026lt;NA\u0026gt; 5 14\rThis updates DT by reference.\n\rfrollmean \u0026amp; frollsum\rNow we are going to explore the frollmean and frollsum functions. These functions allow us to compute rolling means and rolling sums.\nDT[, lapply(.SD, frollmean, 3), .SDcols = numeric_cols]\r## V1 V3 V4\r## 1: NA NA NA\r## 2: NA NA NA\r## 3: 1.666667 NA 10.00000\r## 4: 1.666667 3 10.00000\r## 5: 1.666667 4 11.33333\r#see also ?frollsum\rDT[, lapply(.SD, frollsum, 3), .SDcols = numeric_cols]\r## V1 V3 V4\r## 1: NA NA NA\r## 2: NA NA NA\r## 3: 5 NA 30\r## 4: 5 9 30\r## 5: 5 12 34\r\rcoalesce\rThe fcoalesce function fills missing values in a vector by trying to pull values from one or more candidate vectors.\nx \u0026lt;- c(11L, NA, 13L, NA, 15L, NA)\ry \u0026lt;- c(NA, 12L, 5L, NA, NA, NA)\rz \u0026lt;- c(11L, NA, 1L, 14L, NA, NA)\rfcoalesce(x, y, z)\r## [1] 11 12 13 14 15 NA\rGiven above syntax fcoalesce tries to fill missing values in x by looking at the corresponding elements of y \u0026amp; z. At the second index we find a missing value in x, whereas y = 12L ; z = NA. At the fourth index we find y = NA ; z = 14L. So the new vector becomes 11 12 13 14 15 NA.\n\r\rHelpful links\r\rThe talk: https://www.youtube.com/watch?v=tWx1ooBSxFc\n\rSlides: http://www.user2019.fr/static/pres/t258038.pdf\n\rgithub: https://github.com/Rdatatable, https://github.com/Rdatatable/data.table/wiki\n\r\rSee you soon!\n\r","date":1563062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572349204,"objectID":"e26423f605e6ac5580c036d44c253628","permalink":"/post/data-table-new-and-old-functions/","publishdate":"2019-07-14T00:00:00Z","relpermalink":"/post/data-table-new-and-old-functions/","section":"post","summary":"This is the first post looking at the data.table presentations from useR!2019 which was held in Toulouse from 2019-07-07 to 2019-10-10. For starters we are going to take a look at the presentations from Arun Srinivasan, one of the main developers of data.table. His talk is called THE #RDATATABLEPACKAGE\rfor fast, flexible and memory efficient data wrangling.\nTalk Agenda:\n\rGeneral data.table syntax\rExplaining .SD \u0026amp; .SDcols\rOptimisation \u0026amp; new functionalities\r\rGeneral data.","tags":["data.table","useR!2019"],"title":"data.table - useR!2019 I","type":"post"},{"authors":null,"categories":null,"content":"","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562457600,"objectID":"38befd29e6c76b8c94b6a4c3580b2944","permalink":"/project/offcast-project/","publishdate":"2019-07-07T00:00:00Z","relpermalink":"/project/offcast-project/","section":"project","summary":"A shiny web app that shows forecasts for offshore windenergy","tags":["Forecasting"],"title":"Offcast","type":"project"},{"authors":null,"categories":null,"content":"","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562457600,"objectID":"53b95960201625654a4e617f5d7ab1a2","permalink":"/project/prowea-project/","publishdate":"2019-07-07T00:00:00Z","relpermalink":"/project/prowea-project/","section":"project","summary":"Assessing the power output for offshore wind farms","tags":["offshore"],"title":"ProWEA","type":"project"},{"authors":null,"categories":null,"content":"","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562457600,"objectID":"52547d59ddc869525d028665786d5a02","permalink":"/project/tidecurves-project/","publishdate":"2019-07-07T00:00:00Z","relpermalink":"/project/tidecurves-project/","section":"project","summary":"Generating tide curves from observations (R package)","tags":["R package","tides"],"title":"TideCurves","type":"project"},{"authors":null,"categories":null,"content":"","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562457600,"objectID":"3ce63819f9a4c754c7e4df6675d38167","permalink":"/project/tidetables-project/","publishdate":"2019-07-07T00:00:00Z","relpermalink":"/project/tidetables-project/","section":"project","summary":"Generating tide tables from observations (R package)","tags":["R package","tides"],"title":"TideTables","type":"project"},{"authors":["Moritz Mueller-Navarra"],"categories":[],"content":"\rThe first real post and already a shameless plug for my R course on https://www.udemy.com …\rAs I just uploaded the course I thought, you might be interested in taking this course,\rwhere I talk about the basics of R for beginners. Unfortunately the course is in german for now,\rbut I am going to add english subtitles as soon as I figured out how to correctly use Amazon Transcribe with R to generate german subtitles with a timestamp, which I can then translate into english. I will post more on this topic later this week. Back to the course, as this is a plug for it ;-)\nI mainly teach:\n\rBasics of the R language\rIntro to tidyverse\rIntro to data.table\rPlots (base, ggplot2, plotly)\rIntro to shiny\r\rAs for as I know data.table has been unrecognized (correct me if I am wrong) by most of the instructors of udemy who are teaching R, despite being one of the best package for R! I cover the basics of the package. If you need an intro to data.table, consider taking my course :-).\nMost of the code you will encounter on this blog will start with\nlibrary(data.table)\r## Warning: Paket \u0026#39;data.table\u0026#39; wurde unter R Version 3.6.1 erstellt\rAnyway, you finde my course under this link: https://www.udemy.com/course/r-basics-u/?referralCode=294114E77907E6E07B63, it is called\nR Basics - Programmierung und Datenanalyse.\nSee you soon!\nMoritz\n","date":1562284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572348253,"objectID":"2e164069e624fede569bf787cb5527b7","permalink":"/post/new-r-course-on-udemy-com/","publishdate":"2019-07-05T00:00:00Z","relpermalink":"/post/new-r-course-on-udemy-com/","section":"post","summary":"The first real post and already a shameless plug for my R course on https://www.udemy.com …\rAs I just uploaded the course I thought, you might be interested in taking this course,\rwhere I talk about the basics of R for beginners. Unfortunately the course is in german for now,\rbut I am going to add english subtitles as soon as I figured out how to correctly use Amazon Transcribe with R to generate german subtitles with a timestamp, which I can then translate into english.","tags":["R","R course"],"title":"NEW R COURSE ON UDEMY","type":"post"},{"authors":["Moritz Mueller-Navarra"],"categories":[],"content":"\rAmazon Transcribe \u0026amp; R\rHi, in this post, I will show you some ideas on how to generate subtitles with a time stamp using R and Amazon Transcribe. At first you need at least one mp3 file, or like in my case, 139 files. If you want to use this code, you need to set up an aws (Amazon Web Services) account, which might cost you money, depending on how much you use the services. There is a free tier available on aws, but be careful when using this code! You need and iam role that has access to an s3 folder and is allowed to use Amazon Transcribe.\nIn my case I actually have mp4 video files. I generated the mp3 files with the beautiful ffmpeg. We are not going to cover that in this post, rather showing you the R code for communicating with Amazon S3 and Amazon Transcribe. Your end goal is to create a VTT file, which looks like this:\n1\r00:00:01,000 --\u0026gt; 00:00:06,000\rWillkommen zur ersten Lektion Einf?hrungen er Vektoren und Tim Wir\r2\r00:00:06,000 --\u0026gt; 00:00:11,000\rbesprechen zun?chst die variablen Definition Ich habe euch hier ein\r3\r00:00:11,000 --\u0026gt; 00:00:17,000\rkleines Skript vorbereitet, indem wir der variable A den Wert\r4\r00:00:17,000 --\u0026gt; 00:00:22,000\reins zuordnen im zweiten Schritt die variable A um den\rIf you understand german, you will notice that there are a few errors. It is not too bad though. Now let us jump into the code!\nLoad packages\rlibrary(data.table)\rlibrary(aws.s3)\rlibrary(aws.transcribe)\rlibrary(rjson)\rWe use data.table for some data wrangling, aws.3 \u0026amp; aws.transcribe to communicate with aws and rjson to handle json. Thanks to all package developers!\n\rList files \u0026amp; upload\r#define file path where your mp3 live\r#replace \u0026quot;yourpath\u0026quot; with your path\rfile_path \u0026lt;- file.path(\u0026quot;yourpath\u0026quot;)\r#List files mp3 in your folder\rpath_mp3 \u0026lt;- list.files(file_path, pattern = \u0026quot;.mp3\u0026quot;,\rfull.names = TRUE)\r#basename returns only the file name\rfiles_mp3 \u0026lt;- basename(path_files_mp3)\rNow we upload the mp3 to a s3-bucket\n#define key and secret for your s3 bucket\r#Do not store your key \u0026amp; secret this way\rkey \u0026lt;- \u0026quot;yourkey\u0026quot;\rsecret \u0026lt;- \u0026quot;yoursecret\u0026quot;\r#upload files to s3 bucket\rfor(i in seq_along(path_mp3)) {\rprint(i)\raws.s3::put_object(file = path_mp3[i], object = files_mp3[i], bucket = \u0026quot;yourbucket\u0026quot;, key = key, secret = secret)\r}\r\rStart a transcribe job\rFirst we need to understand what the package aws.transcribe does.\rWe need the start_transcription function\naws.transcribe::start_transcription\r## function (name, url, format = tools::file_ext(url), language = \u0026quot;en-US\u0026quot;, ## hertz = NULL, ...) ## {\r## bod \u0026lt;- list(Media = list(MediaFileUri = url))\r## bod$MediaFormat \u0026lt;- format\r## bod$LanguageCode \u0026lt;- language\r## if (!is.null(hertz)) {\r## bod$MediaSampleRateHertz \u0026lt;- hertz\r## }\r## bod$TranscriptionJobName \u0026lt;- name\r## transcribeHTTP(action = \u0026quot;StartTranscriptionJob\u0026quot;, body = bod, ## ...)\r## }\r## \u0026lt;bytecode: 0x00000000154107d8\u0026gt;\r## \u0026lt;environment: namespace:aws.transcribe\u0026gt;\rThe main takeaway here is that we define a list bod and then call the transcribeHTTP function. We can check the Amazon Transcribe documentation to understand, how we should define a request body which is called bod in this function.\nhttps://docs.aws.amazon.com/de_de/transcribe/latest/dg/API_StartTranscriptionJob.html\nSince I want to define the OutputBucketName, because we are going to write the actual transcribes (json) to a specific bucket, simply add an argument to the start_transcription function. I call the new function StartTranscription.\nStartTranscription \u0026lt;- function (name, url, format = tools::file_ext(url), language = \u0026quot;en-US\u0026quot;, hertz = NULL, outputbucketname = \u0026quot;yourbucketname\u0026quot;, ...) {\rbod \u0026lt;- list(Media = list(MediaFileUri = url))\rbod$MediaFormat \u0026lt;- format\rbod$LanguageCode \u0026lt;- language\rbod$OutputBucketName \u0026lt;- outputbucketname # added\rif (!is.null(hertz)) {\rbod$MediaSampleRateHertz \u0026lt;- hertz\r}\rbod$TranscriptionJobName \u0026lt;- name\rtranscribeHTTP(action = \u0026quot;StartTranscriptionJob\u0026quot;, body = bod, ...)\r}\rThe transcribeHTTP function is a bit more complex.\naws.transcribe::transcribeHTTP\r## function (action, query = list(), body = NULL, version = \u0026quot;v1\u0026quot;, ## region = NULL, key = NULL, secret = NULL, session_token = NULL, ## ...) ## {\r## d_timestamp \u0026lt;- format(Sys.time(), \u0026quot;%Y%m%dT%H%M%SZ\u0026quot;, tz = \u0026quot;UTC\u0026quot;)\r## if (is.null(region) || region == \u0026quot;\u0026quot;) {\r## region \u0026lt;- \u0026quot;us-east-1\u0026quot;\r## }\r## url \u0026lt;- paste0(\u0026quot;https://transcribe.\u0026quot;, region, \u0026quot;.amazonaws.com\u0026quot;)\r## Sig \u0026lt;- signature_v4_auth(datetime = d_timestamp, region = region, ## service = \u0026quot;transcribe\u0026quot;, verb = \u0026quot;POST\u0026quot;, action = \u0026quot;/\u0026quot;, ## query_args = query, canonical_headers = list(host = paste0(\u0026quot;transcribe.\u0026quot;, ## region, \u0026quot;.amazonaws.com\u0026quot;), `x-amz-date` = d_timestamp, ## `X-Amz-Target` = paste0(\u0026quot;Transcribe.\u0026quot;, action), `Content-Type` = \u0026quot;application/x-amz-json-1.1\u0026quot;), ## request_body = if (is.null(body)) ## \u0026quot;\u0026quot;\r## else toJSON(body, auto_unbox = TRUE), key = key, secret = secret, ## session_token = session_token)\r## headers \u0026lt;- list()\r## headers[[\u0026quot;X-Amz-Target\u0026quot;]] \u0026lt;- paste0(\u0026quot;Transcribe.\u0026quot;, action)\r## headers[[\u0026quot;Content-Type\u0026quot;]] \u0026lt;- \u0026quot;application/x-amz-json-1.1\u0026quot;\r## headers[[\u0026quot;x-amz-date\u0026quot;]] \u0026lt;- d_timestamp\r## headers[[\u0026quot;x-amz-content-sha256\u0026quot;]] \u0026lt;- Sig$BodyHash\r## if (!is.null(session_token) \u0026amp;\u0026amp; session_token != \u0026quot;\u0026quot;) {\r## headers[[\u0026quot;x-amz-security-token\u0026quot;]] \u0026lt;- session_token\r## }\r## headers[[\u0026quot;Authorization\u0026quot;]] \u0026lt;- Sig[[\u0026quot;SignatureHeader\u0026quot;]]\r## H \u0026lt;- do.call(add_headers, headers)\r## if (length(query)) {\r## r \u0026lt;- POST(url, H, query = query, body = body, encode = \u0026quot;json\u0026quot;, ## ...)\r## }\r## else {\r## r \u0026lt;- POST(url, H, body = body, encode = \u0026quot;json\u0026quot;, ...)\r## }\r## if (http_error(r)) {\r## x \u0026lt;- fromJSON(content(r, \u0026quot;text\u0026quot;, encoding = \u0026quot;UTF-8\u0026quot;))\r## warn_for_status(r)\r## h \u0026lt;- headers(r)\r## out \u0026lt;- structure(x, headers = h, class = \u0026quot;aws_error\u0026quot;)\r## attr(out, \u0026quot;request_canonical\u0026quot;) \u0026lt;- Sig$CanonicalRequest\r## attr(out, \u0026quot;request_string_to_sign\u0026quot;) \u0026lt;- Sig$StringToSign\r## attr(out, \u0026quot;request_signature\u0026quot;) \u0026lt;- Sig$SignatureHeader\r## }\r## else {\r## out \u0026lt;- try(fromJSON(content(r, \u0026quot;text\u0026quot;, encoding = \u0026quot;UTF-8\u0026quot;)), ## silent = TRUE)\r## if (inherits(out, \u0026quot;try-error\u0026quot;)) {\r## out \u0026lt;- structure(content(r, \u0026quot;text\u0026quot;, encoding = \u0026quot;UTF-8\u0026quot;), ## \u0026quot;unknown\u0026quot;)\r## }\r## }\r## return(out)\r## }\r## \u0026lt;bytecode: 0x0000000015cdebc8\u0026gt;\r## \u0026lt;environment: namespace:aws.transcribe\u0026gt;\rWe call this function inside StartTranscription with action = \"StartTransciptionJob and body = bod. We use the ... argument to pass our secret and key, which are then passed to the POST function from the httr package. If you want more information on how to send requests to aws, please read up on https://docs.aws.amazon.com/de_de/transcribe/latest/dg/CommonParameters.html and https://docs.aws.amazon.com/de_de/general/latest/gr/signature-version-4.html. Thanks to Thomas J. Leeper (aws.s3 \u0026amp; aws.transcribe) that we do not have to fiddle with that for now!\nNow I am defining a url, which points to the s3 bucket where I want to save the transcribes as json.\nfull_url \u0026lt;- paste0(\u0026quot;https://s3.eu-central-1.amazonaws.com/yourbucket/\u0026quot;, files_mp3)\rStart transcription\rWe use files_mp3 as the job name. Please change language and region to your desired values. I simply loop along the vector full_url. I added a Sys.sleep, because i do not want to trigger aws by sending too many requests. I am sure you can get away with way shorter timings. Change the value and test different timings.\nfor(i in seq_along(full_url)) {\rStartTranscription(name = files_mp3[i], language = \u0026quot;de-DE\u0026quot;, url = full_url[i], key = \u0026quot;yourkey\u0026quot;,\rsecret = \u0026quot;yoursecret\u0026quot;, region = \u0026quot;eu-central-1\u0026quot;\r)\rSys.sleep(time = 60)\rpaste(i)\r}\rYou can check the progress in your Amazon Transcribe console.\n\r\rDownload the json files\rI actually need VTT files, because most video editing software are using this file type to include transcriptions. I wrote three helper functions to deal with downloading, formatting the json files and generating VTT files.\nFunctions\rThe first function DownloadTransJson calls FormatJsonObject and WriteVTT after listing and downloading the files from the bucket where we wrote the json files to.\nDownloadTransJson \u0026lt;- function(){\rlist_bucket \u0026lt;- data.table::rbindlist(aws.s3::get_bucket(\rbucket = \u0026quot;yourbucket\u0026quot;, key = \u0026quot;yourkey\u0026quot;, secret = \u0026quot;yoursecret\u0026quot;))\r#only the json files\rlist_bucket \u0026lt;- grep(x = list_bucket$Key, pattern = \u0026quot;mp3.json\u0026quot;, value = TRUE)\r#download files in list_bucket\rfor(i in list_bucket) {\rjson_object \u0026lt;- aws.s3::get_object(object =i,\rbucket = \u0026quot;yourbucket\u0026quot;, key = \u0026quot;yourkey\u0026quot;, secret = \u0026quot;yoursecret\u0026quot;)\rformatted_json \u0026lt;- FormatJsonObject(jsonobject = json_object)\rWriteVTT(i, formatted_json)\r}\r}\rThe FormatJsonObject function formats the response we get from aws.s3::getobject.\nFormatJsonObject \u0026lt;- function(jsonobject){\rtrans_00 \u0026lt;- rjson::fromJSON(rawToChar(jsonobject))\rtranscript \u0026lt;- trans_00$results$transcripts[[1]]$transcript\r#split words\rwords \u0026lt;- unlist(strsplit(transcript, split = \u0026quot; \u0026quot;))\r#bind the list items\rtiming_dt \u0026lt;- rbindlist(trans_00$results$items, fill = TRUE)\r#Getting rid of punctuation for now\rtiming_dt \u0026lt;- timing_dt[type != \u0026quot;punctuation\u0026quot;]\rtiming_dt[, word := words]\r#simple conversion to numeric\rtiming_dt[, start_time := as.numeric(start_time)]\rtiming_dt[, end_time := as.numeric(end_time)]\r#define a group for every ten words\r#so that ten words form a group\rtiming_dt[, group := (1:.N - 1) %/% 10]\r#Collapse word to a phrase by group\rtiming_dt[, phrase := lapply(.SD, paste, collapse = \u0026quot; \u0026quot;), by = group, .SDcols = \u0026quot;word\u0026quot;]\r#get min start_time and max start time for a phrase\rtiming_dt[, `:=` (min_start_time = min(start_time), max_end_time = max(end_time)), by = \u0026quot;group\u0026quot;]\r#Need only one phrase per group, as they are redundant.\runique_dt \u0026lt;- timing_dt[, .SD[1], by = \u0026quot;group\u0026quot;]\runique_dt \u0026lt;- unique_dt[,.SD, .SDcols = c(\u0026quot;phrase\u0026quot;, \u0026quot;min_start_time\u0026quot;, \u0026quot;max_end_time\u0026quot;)]\r#\runique_dt[, time_stamp := paste(paste0(as.ITime(min_start_time),\u0026quot;,000\u0026quot;), paste0(as.ITime(max_end_time),\u0026quot;,000\u0026quot;), sep = \u0026quot; --\u0026gt; \u0026quot;)]\rreturn(unique_dt)\r}\rAnd now simply write a file per transcription as VTT.\nWriteVTT \u0026lt;- function(name, jsondt) {\rfile.create(paste0(name,\u0026quot;.VTT\u0026quot;))\rcon_file \u0026lt;- file(paste0(name,\u0026quot;.VTT\u0026quot;))\r##writing to VTT\r#might be os specific\rwriteLines(paste0(1 : nrow(jsondt),\u0026quot;\\n\u0026quot;,\rjsondt$time_stamp,\u0026quot;\\n\u0026quot;,\rjsondt$phrase,\u0026quot;\\n\u0026quot;), con_file)\r}\rNow we actually call the function.\nDownloadTransJson()\rDone? Not quite. You now need to check your transciptions. Did Amazon Transcribe understand what your were saying? Unfortunately not in every case. It seems like mixing german with english, as I did not “translate” english R expressions into german, is problematic. I am sure it works way better, when you are trying to transcribe english. What are your experiences with Amazon Transcribe ?\nI know one can define a vocabulary to improve the job, which I am going to try for sure!\nHave a great day!\rMoritz\n\r\r\r","date":1562284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567436876,"objectID":"39fdf4732ce4916017eea40abbf1776a","permalink":"/post/using-amazon-transcribe-with-r/","publishdate":"2019-07-05T00:00:00Z","relpermalink":"/post/using-amazon-transcribe-with-r/","section":"post","summary":"Amazon Transcribe \u0026amp; R\rHi, in this post, I will show you some ideas on how to generate subtitles with a time stamp using R and Amazon Transcribe. At first you need at least one mp3 file, or like in my case, 139 files. If you want to use this code, you need to set up an aws (Amazon Web Services) account, which might cost you money, depending on how much you use the services.","tags":["R","aws","aws transcribe","cloud"],"title":"USING AMAZON TRANSCRIBE WITH R","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"}]